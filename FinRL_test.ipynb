{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0976b6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import finrl\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbaac5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (9624, 8)\n"
     ]
    }
   ],
   "source": [
    "df = YahooDownloader(\n",
    "    start_date = '2009-01-01',\n",
    "    end_date = '2021-09-30',\n",
    "    ticker_list = ['AAPL', 'MSFT', 'GOOG']\n",
    ").fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30d7ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "?YahooDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e66a5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>2.758534</td>\n",
       "      <td>746015200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>7.686190</td>\n",
       "      <td>8.015456</td>\n",
       "      <td>7.608980</td>\n",
       "      <td>8.003003</td>\n",
       "      <td>144961322</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>19.530001</td>\n",
       "      <td>20.400000</td>\n",
       "      <td>19.370001</td>\n",
       "      <td>15.162156</td>\n",
       "      <td>50084000</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>3.327500</td>\n",
       "      <td>3.435000</td>\n",
       "      <td>3.311071</td>\n",
       "      <td>2.874955</td>\n",
       "      <td>1181608400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>7.995033</td>\n",
       "      <td>8.250077</td>\n",
       "      <td>7.845593</td>\n",
       "      <td>8.170624</td>\n",
       "      <td>196293007</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9619</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>139.088501</td>\n",
       "      <td>139.606506</td>\n",
       "      <td>135.699997</td>\n",
       "      <td>136.184006</td>\n",
       "      <td>42190000</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9620</th>\n",
       "      <td>2021-09-28</td>\n",
       "      <td>289.799988</td>\n",
       "      <td>290.779999</td>\n",
       "      <td>282.750000</td>\n",
       "      <td>279.674591</td>\n",
       "      <td>43186200</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9621</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>142.470001</td>\n",
       "      <td>144.449997</td>\n",
       "      <td>142.029999</td>\n",
       "      <td>141.582703</td>\n",
       "      <td>74602000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9622</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>137.109695</td>\n",
       "      <td>137.398499</td>\n",
       "      <td>134.250000</td>\n",
       "      <td>134.520996</td>\n",
       "      <td>26338000</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9623</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>285.100006</td>\n",
       "      <td>286.769989</td>\n",
       "      <td>283.010010</td>\n",
       "      <td>280.148102</td>\n",
       "      <td>26353700</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9624 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date        open        high         low       close      volume  \\\n",
       "0     2009-01-02    3.067143    3.251429    3.041429    2.758534   746015200   \n",
       "1     2009-01-02    7.686190    8.015456    7.608980    8.003003   144961322   \n",
       "2     2009-01-02   19.530001   20.400000   19.370001   15.162156    50084000   \n",
       "3     2009-01-05    3.327500    3.435000    3.311071    2.874955  1181608400   \n",
       "4     2009-01-05    7.995033    8.250077    7.845593    8.170624   196293007   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "9619  2021-09-28  139.088501  139.606506  135.699997  136.184006    42190000   \n",
       "9620  2021-09-28  289.799988  290.779999  282.750000  279.674591    43186200   \n",
       "9621  2021-09-29  142.470001  144.449997  142.029999  141.582703    74602000   \n",
       "9622  2021-09-29  137.109695  137.398499  134.250000  134.520996    26338000   \n",
       "9623  2021-09-29  285.100006  286.769989  283.010010  280.148102    26353700   \n",
       "\n",
       "       tic  day  \n",
       "0     AAPL    4  \n",
       "1     GOOG    4  \n",
       "2     MSFT    4  \n",
       "3     AAPL    0  \n",
       "4     GOOG    0  \n",
       "...    ...  ...  \n",
       "9619  GOOG    1  \n",
       "9620  MSFT    1  \n",
       "9621  AAPL    2  \n",
       "9622  GOOG    2  \n",
       "9623  MSFT    2  \n",
       "\n",
       "[9624 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1eabab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "    use_technical_indicator=True,\n",
    "    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "    use_turbulence=True,\n",
    "    user_defined_feature = False\n",
    ")\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db0cb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02ee8fb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'state_space' and 'action_space'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mStockTradingEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mstock_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocessed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mhmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mbuy_cost_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43msell_cost_pct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mreward_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtech_indicator_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTECHNICAL_INDICATORS_LIST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mturbulence_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m140\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;43;03m#                           start_date='2010-01-01',\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;43;03m#                           end_date='2021-09-30',\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43minitial_amount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;43;03m#                           buy_low=True,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;43;03m#                           sell_high=False\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m                     \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'state_space' and 'action_space'"
     ]
    }
   ],
   "source": [
    "env = StockTradingEnv(df=processed,\n",
    "                          stock_dim=len(processed.tic.unique()),\n",
    "                          hmax=100,\n",
    "                          buy_cost_pct=0.001,\n",
    "                          sell_cost_pct=0.001,\n",
    "                          reward_scaling=1e-4,\n",
    "                          tech_indicator_list=config.TECHNICAL_INDICATORS_LIST,\n",
    "                          turbulence_threshold=140,\n",
    "#                           start_date='2010-01-01',\n",
    "#                           end_date='2021-09-30',\n",
    "                          initial_amount=1e6,\n",
    "#                           buy_low=True,\n",
    "#                           sell_high=False\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afff1289",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfinrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menv_stocktrading\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StockTradingEnv\n\u001b[1;32m      3\u001b[0m env \u001b[38;5;241m=\u001b[39m StockTradingEnv(\n\u001b[1;32m      4\u001b[0m         df \u001b[38;5;241m=\u001b[39m processed,\n\u001b[1;32m      5\u001b[0m         stock_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(processed\u001b[38;5;241m.\u001b[39mtic\u001b[38;5;241m.\u001b[39munique()),\n\u001b[1;32m      6\u001b[0m         hmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      7\u001b[0m         buy_cost_pct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      8\u001b[0m         sell_cost_pct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m      9\u001b[0m         reward_scaling \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m,\n\u001b[0;32m---> 10\u001b[0m         state_space \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mstate_space,\n\u001b[1;32m     11\u001b[0m         action_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space,\n\u001b[1;32m     12\u001b[0m         tech_indicator_list \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTECHNICAL_INDICATORS_LIST,\n\u001b[1;32m     13\u001b[0m         turbulence_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m140\u001b[39m,\n\u001b[1;32m     14\u001b[0m         start_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2009-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m         end_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-09-30\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m         initial_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e6\u001b[39m,\n\u001b[1;32m     17\u001b[0m         buy_low \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m         sell_high \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "\n",
    "env = StockTradingEnv(\n",
    "        df = processed,\n",
    "        stock_dim = len(processed.tic.unique()),\n",
    "        hmax = 100,\n",
    "        buy_cost_pct = 0.001,\n",
    "        sell_cost_pct = 0.001,\n",
    "        reward_scaling = 1e-4,\n",
    "        state_space = env.state_space,\n",
    "        action_space = env.action_space,\n",
    "        tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "        turbulence_threshold=140,\n",
    "        start_date = '2009-01-01',\n",
    "        end_date = '2021-09-30',\n",
    "        initial_amount = 1e6,\n",
    "        buy_low = True,\n",
    "        sell_high = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08e2dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finrl import config\n",
    "from finrl import config_tickers\n",
    "from finrl.agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.config import DATA_SAVE_DIR\n",
    "from finrl.config import INDICATORS\n",
    "from finrl.config import RESULTS_DIR\n",
    "from finrl.config import TENSORBOARD_LOG_DIR\n",
    "from finrl.config import TEST_END_DATE\n",
    "from finrl.config import TEST_START_DATE\n",
    "from finrl.config import TRAINED_MODEL_DIR\n",
    "from finrl.config_tickers import DOW_30_TICKER\n",
    "from finrl.main import check_and_make_directories\n",
    "from finrl.meta.data_processor import DataProcessor\n",
    "from finrl.meta.data_processors.func import calc_train_trade_data\n",
    "from finrl.meta.data_processors.func import calc_train_trade_starts_ends_if_rolling\n",
    "from finrl.meta.data_processors.func import date2str\n",
    "from finrl.meta.data_processors.func import str2date\n",
    "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
    "from finrl.meta.preprocessor.preprocessors import data_split\n",
    "from finrl.meta.preprocessor.preprocessors import FeatureEngineer\n",
    "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.plot import backtest_plot\n",
    "from finrl.plot import backtest_stats\n",
    "from finrl.plot import get_baseline\n",
    "from finrl.plot import get_daily_return\n",
    "from finrl.plot import plot_return\n",
    "from finrl.applications.stock_trading.stock_trading import stock_trading\n",
    "import sys\n",
    "sys.path.append(\"../FinRL\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023a947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17f23102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (105011, 8)\n",
      "Successfully added technical indicators\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (3585, 8)\n",
      "Successfully added vix\n",
      "Successfully added turbulence index\n",
      "Stock Dimension: 29, State Space: 291\n",
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to results/a2c\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 100        |\n",
      "|    time_elapsed       | 6          |\n",
      "|    total_timesteps    | 500        |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.3      |\n",
      "|    explained_variance | -5.37      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 99         |\n",
      "|    policy_loss        | -16.2      |\n",
      "|    reward             | 0.17255923 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 1.04       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 200        |\n",
      "|    time_elapsed       | 12         |\n",
      "|    total_timesteps    | 1000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.2      |\n",
      "|    explained_variance | -0.0563    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 199        |\n",
      "|    policy_loss        | -104       |\n",
      "|    reward             | -1.4279287 |\n",
      "|    std                | 1          |\n",
      "|    value_loss         | 7.55       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -256      |\n",
      "|    reward             | 6.0710626 |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 45.4      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | -16.6     |\n",
      "|    reward             | 7.4097466 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4         |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 500        |\n",
      "|    time_elapsed       | 30         |\n",
      "|    total_timesteps    | 2500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 499        |\n",
      "|    policy_loss        | 437        |\n",
      "|    reward             | -4.1835685 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 159        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -26.8     |\n",
      "|    reward             | 1.5432398 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 16.6      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 60.8      |\n",
      "|    reward             | 0.5668169 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.85      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0.0385    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | -65       |\n",
      "|    reward             | 1.1093744 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.5       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 900        |\n",
      "|    time_elapsed       | 55         |\n",
      "|    total_timesteps    | 4500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 899        |\n",
      "|    policy_loss        | 48.8       |\n",
      "|    reward             | -1.0350664 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.79       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -193      |\n",
      "|    reward             | -2.527648 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 24.9      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 7.99      |\n",
      "|    reward             | 0.6964079 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.976     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 70.8      |\n",
      "|    reward             | -2.378392 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.48      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 1300       |\n",
      "|    time_elapsed       | 79         |\n",
      "|    total_timesteps    | 6500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1299       |\n",
      "|    policy_loss        | -448       |\n",
      "|    reward             | -1.7309469 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 165        |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | -10.1     |\n",
      "|    reward             | 2.0300503 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.76      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 1500       |\n",
      "|    time_elapsed       | 91         |\n",
      "|    total_timesteps    | 7500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.5      |\n",
      "|    explained_variance | 0.00571    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1499       |\n",
      "|    policy_loss        | -35.7      |\n",
      "|    reward             | 0.52418554 |\n",
      "|    std                | 1.01       |\n",
      "|    value_loss         | 1.04       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 36.2      |\n",
      "|    reward             | 1.1663742 |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 1.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -103      |\n",
      "|    reward             | 0.6500434 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.44      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 1800       |\n",
      "|    time_elapsed       | 110        |\n",
      "|    total_timesteps    | 9000       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.6      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1799       |\n",
      "|    policy_loss        | 5.03       |\n",
      "|    reward             | 0.05184944 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.43       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 1900       |\n",
      "|    time_elapsed       | 116        |\n",
      "|    total_timesteps    | 9500       |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.7      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 1899       |\n",
      "|    policy_loss        | 115        |\n",
      "|    reward             | 0.96386504 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 8.57       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 122      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 73.5     |\n",
      "|    reward             | -2.43358 |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 12.7     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 2100       |\n",
      "|    time_elapsed       | 128        |\n",
      "|    total_timesteps    | 10500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | -0.169     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2099       |\n",
      "|    policy_loss        | -4.25      |\n",
      "|    reward             | 0.34371644 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 0.228      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | -10.7     |\n",
      "|    reward             | 0.8809111 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 3.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.8     |\n",
      "|    explained_variance | -0.152    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 24.4      |\n",
      "|    reward             | 1.1072161 |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.324     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 74.7      |\n",
      "|    reward             | -3.131309 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 24.2      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 2500       |\n",
      "|    time_elapsed       | 153        |\n",
      "|    total_timesteps    | 12500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.8      |\n",
      "|    explained_variance | -0.0112    |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2499       |\n",
      "|    policy_loss        | -86.7      |\n",
      "|    reward             | -2.6535902 |\n",
      "|    std                | 1.02       |\n",
      "|    value_loss         | 7.69       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 159      |\n",
      "|    total_timesteps    | 13000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -95.2    |\n",
      "|    reward             | 4.580992 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 14.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 165      |\n",
      "|    total_timesteps    | 13500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -41.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 242      |\n",
      "|    reward             | 2.406445 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 37       |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 2800       |\n",
      "|    time_elapsed       | 171        |\n",
      "|    total_timesteps    | 14000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2799       |\n",
      "|    policy_loss        | -36.5      |\n",
      "|    reward             | -0.4185728 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 0.824      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 113       |\n",
      "|    reward             | -1.195913 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 10.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 3000       |\n",
      "|    time_elapsed       | 183        |\n",
      "|    total_timesteps    | 15000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -41.9      |\n",
      "|    explained_variance | -0.132     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 2999       |\n",
      "|    policy_loss        | 39         |\n",
      "|    reward             | -1.5932842 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 2.25       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 189       |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 73        |\n",
      "|    reward             | 1.6359358 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 5.85      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 196      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 290      |\n",
      "|    reward             | 1.217789 |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 54.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 202       |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 18.2      |\n",
      "|    reward             | 0.9624239 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.35      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 3400       |\n",
      "|    time_elapsed       | 208        |\n",
      "|    total_timesteps    | 17000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3399       |\n",
      "|    policy_loss        | -162       |\n",
      "|    reward             | -3.2832916 |\n",
      "|    std                | 1.03       |\n",
      "|    value_loss         | 16.5       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 214       |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.1     |\n",
      "|    explained_variance | -9.06e-06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 21.9      |\n",
      "|    reward             | 1.9880017 |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.319     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 220      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 27.2     |\n",
      "|    reward             | 1.372403 |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.471    |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 3700       |\n",
      "|    time_elapsed       | 226        |\n",
      "|    total_timesteps    | 18500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.2      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3699       |\n",
      "|    policy_loss        | 73.4       |\n",
      "|    reward             | -0.9245831 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 4.02       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 3800       |\n",
      "|    time_elapsed       | 232        |\n",
      "|    total_timesteps    | 19000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.3      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3799       |\n",
      "|    policy_loss        | 49.4       |\n",
      "|    reward             | -0.5819578 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 2.99       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 239       |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.3     |\n",
      "|    explained_variance | -0.0167   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 84.8      |\n",
      "|    reward             | 2.5674462 |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 14.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 4000       |\n",
      "|    time_elapsed       | 245        |\n",
      "|    total_timesteps    | 20000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 3999       |\n",
      "|    policy_loss        | -78.2      |\n",
      "|    reward             | -4.2894025 |\n",
      "|    std                | 1.04       |\n",
      "|    value_loss         | 6.94       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 4100       |\n",
      "|    time_elapsed       | 251        |\n",
      "|    total_timesteps    | 20500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.4      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4099       |\n",
      "|    policy_loss        | 205        |\n",
      "|    reward             | -4.6116433 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 41.2       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 4200       |\n",
      "|    time_elapsed       | 257        |\n",
      "|    total_timesteps    | 21000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0.000936   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4199       |\n",
      "|    policy_loss        | 79.2       |\n",
      "|    reward             | 0.19663656 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 3.64       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 4300       |\n",
      "|    time_elapsed       | 263        |\n",
      "|    total_timesteps    | 21500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.5      |\n",
      "|    explained_variance | 0.163      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4299       |\n",
      "|    policy_loss        | 134        |\n",
      "|    reward             | -1.1571635 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 12.3       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 269       |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | -86       |\n",
      "|    reward             | 1.7068839 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 5.85      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 275      |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -150     |\n",
      "|    reward             | 1.809164 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 19.4     |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 4600       |\n",
      "|    time_elapsed       | 282        |\n",
      "|    total_timesteps    | 23000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4599       |\n",
      "|    policy_loss        | -104       |\n",
      "|    reward             | -1.9343626 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 20.7       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 4700       |\n",
      "|    time_elapsed       | 288        |\n",
      "|    total_timesteps    | 23500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.6      |\n",
      "|    explained_variance | 1.54e-05   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 4699       |\n",
      "|    policy_loss        | -108       |\n",
      "|    reward             | -0.5479632 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 12.2       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 294      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -425     |\n",
      "|    reward             | 4.816214 |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 105      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 300       |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -55.9     |\n",
      "|    reward             | 1.0437354 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 1.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 306       |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -55.3     |\n",
      "|    reward             | 0.5023558 |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 3.75      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 5100       |\n",
      "|    time_elapsed       | 312        |\n",
      "|    total_timesteps    | 25500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5099       |\n",
      "|    policy_loss        | 29.2       |\n",
      "|    reward             | 0.16415249 |\n",
      "|    std                | 1.05       |\n",
      "|    value_loss         | 0.653      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 318       |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 51.6      |\n",
      "|    reward             | 2.7284396 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.79      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 325       |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 32.9      |\n",
      "|    reward             | 2.8804457 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.72      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 331       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -188      |\n",
      "|    reward             | 4.3874884 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 27.9      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 5500       |\n",
      "|    time_elapsed       | 337        |\n",
      "|    total_timesteps    | 27500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5499       |\n",
      "|    policy_loss        | 174        |\n",
      "|    reward             | -12.827584 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 87         |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 5600       |\n",
      "|    time_elapsed       | 343        |\n",
      "|    total_timesteps    | 28000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.8      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5599       |\n",
      "|    policy_loss        | 21.6       |\n",
      "|    reward             | 0.23027852 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 0.696      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 349       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | -255      |\n",
      "|    reward             | 2.5576491 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 36.6      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 5800       |\n",
      "|    time_elapsed       | 356        |\n",
      "|    total_timesteps    | 29000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -42.9      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 5799       |\n",
      "|    policy_loss        | 48.6       |\n",
      "|    reward             | 0.49845332 |\n",
      "|    std                | 1.06       |\n",
      "|    value_loss         | 2.78       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 81          |\n",
      "|    iterations         | 5900        |\n",
      "|    time_elapsed       | 362         |\n",
      "|    total_timesteps    | 29500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 5899        |\n",
      "|    policy_loss        | -75.2       |\n",
      "|    reward             | -0.73465806 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 3.24        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 368       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 78.4      |\n",
      "|    reward             | 3.3854446 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 12.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 374      |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | -214     |\n",
      "|    reward             | 5.650005 |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 30.7     |\n",
      "------------------------------------\n",
      "day: 3439, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4259682.81\n",
      "total_reward: 3259682.81\n",
      "total_cost: 5742.19\n",
      "total_trades: 49185\n",
      "Sharpe: 0.729\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 81          |\n",
      "|    iterations         | 6200        |\n",
      "|    time_elapsed       | 380         |\n",
      "|    total_timesteps    | 31000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -42.9       |\n",
      "|    explained_variance | 0.353       |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 6199        |\n",
      "|    policy_loss        | -4.34       |\n",
      "|    reward             | -0.49579397 |\n",
      "|    std                | 1.06        |\n",
      "|    value_loss         | 1.17        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 386       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | -65.1     |\n",
      "|    reward             | -1.049195 |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.95      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 392       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | -9.57     |\n",
      "|    reward             | 1.2979798 |\n",
      "|    std                | 1.07      |\n",
      "|    value_loss         | 0.0819    |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 6500       |\n",
      "|    time_elapsed       | 399        |\n",
      "|    total_timesteps    | 32500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.1      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6499       |\n",
      "|    policy_loss        | -63.3      |\n",
      "|    reward             | 0.48430043 |\n",
      "|    std                | 1.07       |\n",
      "|    value_loss         | 4.28       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 6600     |\n",
      "|    time_elapsed       | 405      |\n",
      "|    total_timesteps    | 33000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6599     |\n",
      "|    policy_loss        | 3.94     |\n",
      "|    reward             | 2.579281 |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.495    |\n",
      "------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 81            |\n",
      "|    iterations         | 6700          |\n",
      "|    time_elapsed       | 411           |\n",
      "|    total_timesteps    | 33500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6699          |\n",
      "|    policy_loss        | -166          |\n",
      "|    reward             | -0.0150592625 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 19.4          |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 6800       |\n",
      "|    time_elapsed       | 417        |\n",
      "|    total_timesteps    | 34000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.2      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6799       |\n",
      "|    policy_loss        | 44.4       |\n",
      "|    reward             | -1.7112039 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 8.82       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 423       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.3     |\n",
      "|    explained_variance | -13       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 78.9      |\n",
      "|    reward             | 0.9961461 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 16.2      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 7000       |\n",
      "|    time_elapsed       | 429        |\n",
      "|    total_timesteps    | 35000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 6999       |\n",
      "|    policy_loss        | -28.4      |\n",
      "|    reward             | -1.0725936 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.519      |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 81          |\n",
      "|    iterations         | 7100        |\n",
      "|    time_elapsed       | 435         |\n",
      "|    total_timesteps    | 35500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.4       |\n",
      "|    explained_variance | 1.19e-07    |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7099        |\n",
      "|    policy_loss        | -1.19       |\n",
      "|    reward             | 0.049803134 |\n",
      "|    std                | 1.08        |\n",
      "|    value_loss         | 0.145       |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 7200       |\n",
      "|    time_elapsed       | 441        |\n",
      "|    total_timesteps    | 36000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7199       |\n",
      "|    policy_loss        | -64.5      |\n",
      "|    reward             | -0.7622921 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 2.81       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 7300       |\n",
      "|    time_elapsed       | 448        |\n",
      "|    total_timesteps    | 36500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.4      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7299       |\n",
      "|    policy_loss        | -23.9      |\n",
      "|    reward             | -0.6911486 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 0.85       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 454       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | -108      |\n",
      "|    reward             | 3.5952196 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 6.95      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 460       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 74.6      |\n",
      "|    reward             | 0.6074029 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 4.4       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 466       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | -0.177    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -28.1     |\n",
      "|    reward             | 1.6773605 |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.643     |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 7700       |\n",
      "|    time_elapsed       | 472        |\n",
      "|    total_timesteps    | 38500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 5.96e-08   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7699       |\n",
      "|    policy_loss        | -124       |\n",
      "|    reward             | -0.5700231 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 33.9       |\n",
      "--------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 7800     |\n",
      "|    time_elapsed       | 478      |\n",
      "|    total_timesteps    | 39000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7799     |\n",
      "|    policy_loss        | 19.8     |\n",
      "|    reward             | 2.33824  |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 1.2      |\n",
      "------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 7900       |\n",
      "|    time_elapsed       | 485        |\n",
      "|    total_timesteps    | 39500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 7899       |\n",
      "|    policy_loss        | 150        |\n",
      "|    reward             | -1.7236732 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 18.1       |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 8000     |\n",
      "|    time_elapsed       | 491      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 7999     |\n",
      "|    policy_loss        | 636      |\n",
      "|    reward             | -0.68141 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 216      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 497      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -139     |\n",
      "|    reward             | 7.853616 |\n",
      "|    std                | 1.09     |\n",
      "|    value_loss         | 32.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 503       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -325      |\n",
      "|    reward             | 4.1632423 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 74.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 509       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 174       |\n",
      "|    reward             | 1.5054228 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 14.3      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 8400       |\n",
      "|    time_elapsed       | 515        |\n",
      "|    total_timesteps    | 42000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | -1.19e-07  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8399       |\n",
      "|    policy_loss        | -136       |\n",
      "|    reward             | -3.9181175 |\n",
      "|    std                | 1.08       |\n",
      "|    value_loss         | 17.4       |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 8500       |\n",
      "|    time_elapsed       | 522        |\n",
      "|    total_timesteps    | 42500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | 0.0286     |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8499       |\n",
      "|    policy_loss        | -22.7      |\n",
      "|    reward             | 0.97841394 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 0.795      |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 528       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 213       |\n",
      "|    reward             | 1.9614799 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 30.5      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 534       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | 0.002     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 52.8      |\n",
      "|    reward             | 1.5805193 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 4.28      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 8800       |\n",
      "|    time_elapsed       | 540        |\n",
      "|    total_timesteps    | 44000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.5      |\n",
      "|    explained_variance | -0.000504  |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8799       |\n",
      "|    policy_loss        | 233        |\n",
      "|    reward             | -3.5540137 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 50.7       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 546       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -0.00158  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 281       |\n",
      "|    reward             | 5.7569914 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 109       |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 9000       |\n",
      "|    time_elapsed       | 552        |\n",
      "|    total_timesteps    | 45000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.6      |\n",
      "|    explained_variance | 0          |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 8999       |\n",
      "|    policy_loss        | -152       |\n",
      "|    reward             | -1.1246674 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 16.2       |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 81          |\n",
      "|    iterations         | 9100        |\n",
      "|    time_elapsed       | 559         |\n",
      "|    total_timesteps    | 45500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.6       |\n",
      "|    explained_variance | 0.0408      |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9099        |\n",
      "|    policy_loss        | -49.8       |\n",
      "|    reward             | 0.076889135 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 1.74        |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 9200       |\n",
      "|    time_elapsed       | 565        |\n",
      "|    total_timesteps    | 46000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.7      |\n",
      "|    explained_variance | -0.01      |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9199       |\n",
      "|    policy_loss        | -174       |\n",
      "|    reward             | 0.15359265 |\n",
      "|    std                | 1.09       |\n",
      "|    value_loss         | 27         |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 571       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 21.6      |\n",
      "|    reward             | 7.2380066 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 8.49      |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 81          |\n",
      "|    iterations         | 9400        |\n",
      "|    time_elapsed       | 577         |\n",
      "|    total_timesteps    | 47000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.7       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9399        |\n",
      "|    policy_loss        | 332         |\n",
      "|    reward             | 0.042863615 |\n",
      "|    std                | 1.09        |\n",
      "|    value_loss         | 59.7        |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 583       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -106      |\n",
      "|    reward             | 1.7867011 |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 8.98      |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 9600       |\n",
      "|    time_elapsed       | 589        |\n",
      "|    total_timesteps    | 48000      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.8      |\n",
      "|    explained_variance | 1.79e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9599       |\n",
      "|    policy_loss        | 105        |\n",
      "|    reward             | -3.6937034 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 15.6       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 596       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -71.3     |\n",
      "|    reward             | 0.3128041 |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 3.17      |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 81          |\n",
      "|    iterations         | 9800        |\n",
      "|    time_elapsed       | 602         |\n",
      "|    total_timesteps    | 49000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -43.9       |\n",
      "|    explained_variance | 0.00678     |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9799        |\n",
      "|    policy_loss        | -4.64       |\n",
      "|    reward             | -0.16019474 |\n",
      "|    std                | 1.1         |\n",
      "|    value_loss         | 3.8         |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| time/                 |            |\n",
      "|    fps                | 81         |\n",
      "|    iterations         | 9900       |\n",
      "|    time_elapsed       | 608        |\n",
      "|    total_timesteps    | 49500      |\n",
      "| train/                |            |\n",
      "|    entropy_loss       | -43.9      |\n",
      "|    explained_variance | 1.19e-07   |\n",
      "|    learning_rate      | 0.0007     |\n",
      "|    n_updates          | 9899       |\n",
      "|    policy_loss        | 59.6       |\n",
      "|    reward             | -0.8889801 |\n",
      "|    std                | 1.1        |\n",
      "|    value_loss         | 3.16       |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 614       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 148       |\n",
      "|    reward             | -0.999418 |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/ddpg\n",
      "day: 3439, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4781054.84\n",
      "total_reward: 3781054.84\n",
      "total_cost: 999.00\n",
      "total_trades: 65341\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 40         |\n",
      "|    time_elapsed    | 339        |\n",
      "|    total_timesteps | 13760      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -21.1      |\n",
      "|    critic_loss     | 67.8       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 10320      |\n",
      "|    reward          | -3.9185128 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 37         |\n",
      "|    time_elapsed    | 741        |\n",
      "|    total_timesteps | 27520      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -15.2      |\n",
      "|    critic_loss     | 3.56       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 24080      |\n",
      "|    reward          | -3.9185128 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 36         |\n",
      "|    time_elapsed    | 1142       |\n",
      "|    total_timesteps | 41280      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | -12.9      |\n",
      "|    critic_loss     | 2.5        |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 37840      |\n",
      "|    reward          | -3.9185128 |\n",
      "-----------------------------------\n",
      "day: 3439, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 4781054.84\n",
      "total_reward: 3781054.84\n",
      "total_cost: 999.00\n",
      "total_trades: 65341\n",
      "Sharpe: 0.684\n",
      "=================================\n",
      "{'n_steps': 2048, 'ent_coef': 0.01, 'learning_rate': 0.00025, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to results/ppo\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    fps             | 86         |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 23         |\n",
      "|    total_timesteps | 2048       |\n",
      "| train/             |            |\n",
      "|    reward          | 0.05641837 |\n",
      "-----------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013270862 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0209     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.55        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    reward               | -5.392535   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 84          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016215807 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | 0.00194     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 58.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    reward               | -2.59368    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015818646 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.2       |\n",
      "|    explained_variance   | -0.0154     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 5.09        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | -1.3900222  |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 18.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014509131 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.00586    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    reward               | -9.349717   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016942037 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | 0.00924     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    reward               | 0.9005347   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 93.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020266235 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.3       |\n",
      "|    explained_variance   | -0.0295     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    reward               | 0.619063    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 195         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021506388 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.4       |\n",
      "|    explained_variance   | -0.00579    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    reward               | 3.2877839   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016298704 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.5       |\n",
      "|    explained_variance   | 0.0016      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.33        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    reward               | 0.28086963  |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 20.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 83         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 245        |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02044121 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.5      |\n",
      "|    explained_variance   | 0.00623    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 30.9       |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    reward               | -0.7692332 |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 53.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 83         |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 270        |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01910738 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.6      |\n",
      "|    explained_variance   | -0.0147    |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 100        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    reward               | -1.3242861 |\n",
      "|    std                  | 1.02       |\n",
      "|    value_loss           | 62.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 294         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020391308 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.6       |\n",
      "|    explained_variance   | 0.0526      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 17.6        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    reward               | 0.989817    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017372943 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.00143    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 64.6        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    reward               | 4.1527205   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 94.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 3439, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3247532.32\n",
      "total_reward: 2247532.32\n",
      "total_cost: 428648.46\n",
      "total_trades: 93038\n",
      "Sharpe: 0.548\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028366892 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.7       |\n",
      "|    explained_variance   | -0.0527     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 9.63        |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    reward               | 2.6699748   |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 20.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024576457 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.00756     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 74.1        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    reward               | -6.4312696  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 88.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024207052 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.00698     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 296         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    reward               | -0.4499357  |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028460916 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.8       |\n",
      "|    explained_variance   | 0.042       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    reward               | 1.5581083   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024239251 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -41.9       |\n",
      "|    explained_variance   | -0.00631    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 42.5        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    reward               | 6.999263    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 89.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027169779 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.00906     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 7.66        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    reward               | 0.38815314  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027935706 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42         |\n",
      "|    explained_variance   | 0.00527     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    reward               | -2.153125   |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 517         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021668848 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | -0.00506    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    reward               | -2.7465172  |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 81.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.03319795  |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.1       |\n",
      "|    explained_variance   | 0.012       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    reward               | -0.89389265 |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019839237 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | 0.00783     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 88.9        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    reward               | 1.4167002   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 595         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028858019 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.2       |\n",
      "|    explained_variance   | -0.0239     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    reward               | 1.1394231   |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 620         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034793705 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -42.3       |\n",
      "|    explained_variance   | 0.00294     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 82.3        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    reward               | 6.578063    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0001, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n",
      "Logging to results/sac\n",
      "day: 3439, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 3745799.63\n",
      "total_reward: 2745799.63\n",
      "total_cost: 345667.30\n",
      "total_trades: 76515\n",
      "Sharpe: 0.588\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 28         |\n",
      "|    time_elapsed    | 475        |\n",
      "|    total_timesteps | 13760      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 954        |\n",
      "|    critic_loss     | 430        |\n",
      "|    ent_coef        | 0.233      |\n",
      "|    ent_coef_loss   | -43.3      |\n",
      "|    learning_rate   | 0.0001     |\n",
      "|    n_updates       | 13659      |\n",
      "|    reward          | -2.6417978 |\n",
      "-----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 955       |\n",
      "|    total_timesteps | 27520     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 272       |\n",
      "|    critic_loss     | 166       |\n",
      "|    ent_coef        | 0.0567    |\n",
      "|    ent_coef_loss   | -124      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 27419     |\n",
      "|    reward          | -4.306937 |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 1431      |\n",
      "|    total_timesteps | 41280     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 91.1      |\n",
      "|    critic_loss     | 50.3      |\n",
      "|    ent_coef        | 0.0148    |\n",
      "|    ent_coef_loss   | -123      |\n",
      "|    learning_rate   | 0.0001    |\n",
      "|    n_updates       | 41179     |\n",
      "|    reward          | -3.615705 |\n",
      "----------------------------------\n",
      "day: 3439, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5123889.73\n",
      "total_reward: 4123889.73\n",
      "total_cost: 5109.82\n",
      "total_trades: 54506\n",
      "Sharpe: 0.698\n",
      "=================================\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to results/td3\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 4          |\n",
      "|    fps             | 41         |\n",
      "|    time_elapsed    | 327        |\n",
      "|    total_timesteps | 13760      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 44.9       |\n",
      "|    critic_loss     | 738        |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 10320      |\n",
      "|    reward          | -5.0926723 |\n",
      "-----------------------------------\n",
      "day: 3439, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 5410911.48\n",
      "total_reward: 4410911.48\n",
      "total_cost: 999.00\n",
      "total_trades: 55024\n",
      "Sharpe: 0.736\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 38         |\n",
      "|    time_elapsed    | 712        |\n",
      "|    total_timesteps | 27520      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 25.6       |\n",
      "|    critic_loss     | 196        |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 24080      |\n",
      "|    reward          | -5.0926723 |\n",
      "-----------------------------------\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 12         |\n",
      "|    fps             | 37         |\n",
      "|    time_elapsed    | 1096       |\n",
      "|    total_timesteps | 41280      |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 24.2       |\n",
      "|    critic_loss     | 49.3       |\n",
      "|    learning_rate   | 0.001      |\n",
      "|    n_updates       | 37840      |\n",
      "|    reward          | -5.0926723 |\n",
      "-----------------------------------\n",
      "hit end!\n",
      "hit end!\n",
      "hit end!\n",
      "hit end!\n",
      "hit end!\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (146, 8)\n",
      "Annual return          0.066946\n",
      "Cumulative returns     0.037989\n",
      "Annual volatility      0.184245\n",
      "Sharpe ratio           0.445562\n",
      "Calmar ratio           0.592967\n",
      "Stability              0.316147\n",
      "Max drawdown          -0.112899\n",
      "Omega ratio            1.076490\n",
      "Sortino ratio          0.661248\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.222868\n",
      "Daily value at risk   -0.022887\n",
      "dtype: float64\n",
      "\n",
      "stats of DJI: \n",
      " Annual return          0.066946\n",
      "Cumulative returns     0.037989\n",
      "Annual volatility      0.184245\n",
      "Sharpe ratio           0.445562\n",
      "Calmar ratio           0.592967\n",
      "Stability              0.316147\n",
      "Max drawdown          -0.112899\n",
      "Omega ratio            1.076490\n",
      "Sortino ratio          0.661248\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.222868\n",
      "Daily value at risk   -0.022887\n",
      "dtype: float64\n",
      "Annual return          0.111963\n",
      "Cumulative returns     0.062968\n",
      "Annual volatility      0.175081\n",
      "Sharpe ratio           0.697462\n",
      "Calmar ratio           1.206186\n",
      "Stability              0.357417\n",
      "Max drawdown          -0.092824\n",
      "Omega ratio            1.122241\n",
      "Sortino ratio          1.022943\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.227602\n",
      "Daily value at risk   -0.021574\n",
      "dtype: float64\n",
      "\n",
      "stats of A2C: \n",
      " Annual return          0.111963\n",
      "Cumulative returns     0.062968\n",
      "Annual volatility      0.175081\n",
      "Sharpe ratio           0.697462\n",
      "Calmar ratio           1.206186\n",
      "Stability              0.357417\n",
      "Max drawdown          -0.092824\n",
      "Omega ratio            1.122241\n",
      "Sortino ratio          1.022943\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.227602\n",
      "Daily value at risk   -0.021574\n",
      "dtype: float64\n",
      "Annual return          0.114981\n",
      "Cumulative returns     0.064627\n",
      "Annual volatility      0.205046\n",
      "Sharpe ratio           0.636173\n",
      "Calmar ratio           0.981742\n",
      "Stability              0.401489\n",
      "Max drawdown          -0.117119\n",
      "Omega ratio            1.108990\n",
      "Sortino ratio          0.959791\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.144328\n",
      "Daily value at risk   -0.025316\n",
      "dtype: float64\n",
      "\n",
      "stats of DDPG: \n",
      " Annual return          0.114981\n",
      "Cumulative returns     0.064627\n",
      "Annual volatility      0.205046\n",
      "Sharpe ratio           0.636173\n",
      "Calmar ratio           0.981742\n",
      "Stability              0.401489\n",
      "Max drawdown          -0.117119\n",
      "Omega ratio            1.108990\n",
      "Sortino ratio          0.959791\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.144328\n",
      "Daily value at risk   -0.025316\n",
      "dtype: float64\n",
      "Annual return          0.131990\n",
      "Cumulative returns     0.073942\n",
      "Annual volatility      0.179357\n",
      "Sharpe ratio           0.785190\n",
      "Calmar ratio           1.199146\n",
      "Stability              0.439266\n",
      "Max drawdown          -0.110070\n",
      "Omega ratio            1.140121\n",
      "Sortino ratio          1.173660\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.142528\n",
      "Daily value at risk   -0.022038\n",
      "dtype: float64\n",
      "\n",
      "stats of TD3: \n",
      " Annual return          0.131990\n",
      "Cumulative returns     0.073942\n",
      "Annual volatility      0.179357\n",
      "Sharpe ratio           0.785190\n",
      "Calmar ratio           1.199146\n",
      "Stability              0.439266\n",
      "Max drawdown          -0.110070\n",
      "Omega ratio            1.140121\n",
      "Sortino ratio          1.173660\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.142528\n",
      "Daily value at risk   -0.022038\n",
      "dtype: float64\n",
      "Annual return          0.253959\n",
      "Cumulative returns     0.139074\n",
      "Annual volatility      0.174625\n",
      "Sharpe ratio           1.391837\n",
      "Calmar ratio           3.864003\n",
      "Stability              0.685955\n",
      "Max drawdown          -0.065724\n",
      "Omega ratio            1.265537\n",
      "Sortino ratio          2.277167\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.140710\n",
      "Daily value at risk   -0.021036\n",
      "dtype: float64\n",
      "\n",
      "stats of PPO: \n",
      " Annual return          0.253959\n",
      "Cumulative returns     0.139074\n",
      "Annual volatility      0.174625\n",
      "Sharpe ratio           1.391837\n",
      "Calmar ratio           3.864003\n",
      "Stability              0.685955\n",
      "Max drawdown          -0.065724\n",
      "Omega ratio            1.265537\n",
      "Sortino ratio          2.277167\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.140710\n",
      "Daily value at risk   -0.021036\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annual return          0.070515\n",
      "Cumulative returns     0.039986\n",
      "Annual volatility      0.190425\n",
      "Sharpe ratio           0.454824\n",
      "Calmar ratio           0.619882\n",
      "Stability              0.327614\n",
      "Max drawdown          -0.113756\n",
      "Omega ratio            1.078982\n",
      "Sortino ratio          0.674297\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.169456\n",
      "Daily value at risk   -0.023648\n",
      "dtype: float64\n",
      "\n",
      "stats of SAC: \n",
      " Annual return          0.070515\n",
      "Cumulative returns     0.039986\n",
      "Annual volatility      0.190425\n",
      "Sharpe ratio           0.454824\n",
      "Calmar ratio           0.619882\n",
      "Stability              0.327614\n",
      "Max drawdown          -0.113756\n",
      "Omega ratio            1.078982\n",
      "Sortino ratio          0.674297\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             1.169456\n",
      "Daily value at risk   -0.023648\n",
      "dtype: float64\n",
      "result:             date           DJI           A2C          DDPG           TD3  \\\n",
      "0    2022-09-01  1.000000e+06  1.000000e+06  1.000000e+06  1.000000e+06   \n",
      "1    2022-09-02  9.893235e+05  9.975142e+05  9.972532e+05  9.969268e+05   \n",
      "2    2022-09-06  9.838542e+05  9.971106e+05  9.929692e+05  9.950191e+05   \n",
      "3    2022-09-07  9.976264e+05  1.004304e+06  1.004235e+06  1.006474e+06   \n",
      "4    2022-09-08  1.003731e+06  1.010316e+06  1.011073e+06  1.014020e+06   \n",
      "..          ...           ...           ...           ...           ...   \n",
      "140  2023-03-24  1.018357e+06  1.040910e+06  1.040924e+06  1.055895e+06   \n",
      "141  2023-03-27  1.024502e+06  1.048903e+06  1.046692e+06  1.063792e+06   \n",
      "142  2023-03-28  1.023307e+06  1.047361e+06  1.046574e+06  1.062912e+06   \n",
      "143  2023-03-29  1.033522e+06  1.055034e+06  1.059356e+06  1.070593e+06   \n",
      "144  2023-03-30  1.037989e+06  1.062968e+06  1.064627e+06  1.073942e+06   \n",
      "\n",
      "              PPO           SAC  \n",
      "0    1.000000e+06  1.000000e+06  \n",
      "1    9.997197e+05  9.975151e+05  \n",
      "2    9.993895e+05  9.952872e+05  \n",
      "3    1.000535e+06  1.002974e+06  \n",
      "4    1.001253e+06  1.005111e+06  \n",
      "..            ...           ...  \n",
      "140  1.117124e+06  1.022941e+06  \n",
      "141  1.126338e+06  1.029362e+06  \n",
      "142  1.122922e+06  1.024862e+06  \n",
      "143  1.136485e+06  1.034585e+06  \n",
      "144  1.139074e+06  1.039986e+06  \n",
      "\n",
      "[145 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n",
      "/home/ubuntu/miniconda3/lib/python3.9/site-packages/pyfolio/timeseries.py:724: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  stats = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final return:  {'DJI': 0.0379894925292541, 'A2C': 0.06296807368739721, 'DDPG': 0.06462717246813376, 'TD3': 0.07394194942335908, 'PPO': 0.13907407500747615, 'SAC': 0.03998637135493244}\n"
     ]
    }
   ],
   "source": [
    "train_start_date = \"2009-01-01\"\n",
    "train_end_date = \"2022-09-01\"\n",
    "trade_start_date = \"2022-09-01\"\n",
    "trade_end_date = \"2023-11-01\"\n",
    "if_store_actions = True\n",
    "if_store_result = True\n",
    "if_using_a2c = True\n",
    "if_using_ddpg = True\n",
    "if_using_ppo = True\n",
    "if_using_sac = True\n",
    "if_using_td3 = True\n",
    "\n",
    "stock_trading(\n",
    "    train_start_date=train_start_date,\n",
    "    train_end_date=train_end_date,\n",
    "    trade_start_date=trade_start_date,\n",
    "    trade_end_date=trade_end_date,\n",
    "    if_store_actions=if_store_actions,\n",
    "    if_store_result=if_store_result,\n",
    "    if_using_a2c=if_using_a2c,\n",
    "    if_using_ddpg=if_using_ddpg,\n",
    "    if_using_ppo=if_using_ppo,\n",
    "    if_using_sac=if_using_sac,\n",
    "    if_using_td3=if_using_td3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f8e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "?stock_trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ade950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38af46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce72701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2fd2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
