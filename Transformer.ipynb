{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, pytz\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "import wandb\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import alpaca\n",
    "from alpaca_trade_api import REST\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import pytz\n",
    "\n",
    "### get stock data\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "\n",
    "import sys\n",
    "sys.path = sys.path + ['../']\n",
    "\n",
    "import my_secrets\n",
    "import pickle\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_code='TQQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'./historical_price_data/{stock_code}.csv'\n",
    "data = pd.read_csv(path,index_col=0)\n",
    "data.index = pd.Series([i.replace(tzinfo=None) for i in pd.to_datetime(data.index)]).dt.tz_localize(pytz.timezone('US/Eastern'))\n",
    "a = data.resample('1min').mean().dropna()\n",
    "a['change_rate'] = (a['close'] - a['open'])/a['open']\n",
    "a['change_bi'] = np.where((a['close'] - a['open'])>0,1,0)\n",
    "a['date'] = pd.to_datetime([i.date() for i in a.index])\n",
    "a['year'] = a.date.dt.year\n",
    "a['WOY'] = a.date.dt.week\n",
    "a['WOY_year'] = [str(a)+str(b) for a,b in zip(a['WOY'],a['year'])]\n",
    "a['MOY'] = a.date.dt.month\n",
    "a['MOY_year'] = [str(a)+str(b) for a,b in zip(a['MOY'],a['year'])]\n",
    "a['DOW'] = a.date.dt.day_of_week\n",
    "a['DOY'] = a.date.dt.day_of_year\n",
    "a['DOY_year'] = [str(a)+str(b) for a,b in zip(a['DOY'],a['year'])]\n",
    "a['MOD'] = [i.hour*60+i.minute for i in a.index]\n",
    "a['HOD'] = [i.hour for i in a.index]\n",
    "a = a[(a.MOD>=9.5*60) & (a.MOD<=16*60)]\n",
    "a['change_rate'] = (a['close'] - a['open'])/a['open']\n",
    "whole_sequence = a['change_rate'].values\n",
    "del a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myloader():\n",
    "    def __init__(self, whole_sequence, past_feature_size=150000, batch_size=10):\n",
    "        self.whole_sequence = whole_sequence\n",
    "        self.past_feature_size = past_feature_size\n",
    "        self.batch_size = batch_size\n",
    "        self.total = int(len(whole_sequence)/batch_size)\n",
    "    \n",
    "    def get_data(self):\n",
    "        batch_size = self.batch_size\n",
    "        ## random idx\n",
    "        \n",
    "        idx_pool = list(range(len(self.whole_sequence)))[self.past_feature_size+10:]\n",
    "        np.random.shuffle(idx_pool)\n",
    "        \n",
    "        x_list = []\n",
    "        y_list = []\n",
    "        for idx in idx_pool:\n",
    "            if idx<=self.past_feature_size+10:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                x = np.expand_dims(\n",
    "                    self.whole_sequence[idx-self.past_feature_size:idx].reshape(self.past_feature_size,-1),\n",
    "                    axis=0\n",
    "                )\n",
    "                x = torch.tensor(x).float()*100\n",
    "                y = torch.tensor(self.whole_sequence[idx]).reshape(1,-1).float()*100\n",
    "                x_list.append(x)\n",
    "                y_list.append(y)\n",
    "                \n",
    "                if not len(x_list)>=batch_size:\n",
    "                    continue\n",
    "                else:\n",
    "                    x = torch.cat(x_list)\n",
    "                    y = torch.cat(y_list)\n",
    "                    x_list = []\n",
    "                    y_list = []\n",
    "                    yield x,y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SEQUENCE_LENGTH = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.82051282051282"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5000/60/6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309266"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_sequence[0:int(len(whole_sequence)*0.6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180406"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_sequence[int(len(whole_sequence)*0.65):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515444"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = myloader(whole_sequence[0:int(len(whole_sequence)*0.6)],\n",
    "                        INPUT_SEQUENCE_LENGTH,\n",
    "                        batch_size=50\n",
    "                       )\n",
    "val_loader = myloader(whole_sequence[int(len(whole_sequence)*0.65):],\n",
    "                        INPUT_SEQUENCE_LENGTH,\n",
    "                      batch_size=50\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPricePredictionModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1, dropout=0.2):\n",
    "        super(StockPricePredictionModel, self).__init__()\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(input_size, nhead=1, dim_feedforward=hidden_size, dropout=dropout, batch_first=True),\n",
    "            num_layers\n",
    "        )\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = self.fc1(x[:,-1,:])\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1  # Number of features for each minute\n",
    "hidden_size = 64  # Size of the hidden layer\n",
    "output_size = 1  # Predicting one value: the minute-level price change\n",
    "num_layers = 1  # Number of transformer encoder layers\n",
    "dropout = 0.2  # Dropout probability\n",
    "model = StockPricePredictionModel(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "model = model.to('cpu').float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/6185 [06:49<63:54:09, 37.26s/it]\n",
      "  0%|          | 11/3608 [01:54<10:23:25, 10.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 0.033312346786260605, val_loss: 0.04829886132343249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/6185 [07:10<67:05:36, 39.12s/it]\n",
      "  0%|          | 11/3608 [01:53<10:21:06, 10.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, train_loss: 0.03831720521504229, val_loss: 0.04056826470927759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/6185 [02:35<88:57:50, 51.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, y)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     17\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(100):\n",
    "    \n",
    "    #### train\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    optimizer.zero_grad()\n",
    "    for batch_count,(x,y) in tqdm(enumerate(train_loader.get_data()), total = train_loader.total):\n",
    "        if batch_count>100:\n",
    "            break\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            train_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "#         print(f'loss: {loss.item():.4f}')\n",
    "    \n",
    "    ### eval\n",
    "    model.eval()\n",
    "    for batch_count,(x,y) in tqdm(enumerate(val_loader.get_data()), total = val_loader.total):\n",
    "        if batch_count>100:\n",
    "            break\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y)\n",
    "        with torch.no_grad():\n",
    "            val_losses.append(loss.item())\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, train_loss: {np.nanmean(train_losses)}, val_loss: {np.nanmean(val_losses)}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e9867b585c0f10e2eb480253e40cab44b53d9f15cdd7fb9c79b17a5cb2fa039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
